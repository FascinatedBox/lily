# This script generates the following:
#
# src/lily_parser_data.h
#
# * constants: The constant table holds names that are immediate values, such as
#              __file__, true, unit, and so on.
#
# * keywords: The keyword table holds names that are important keywords, such as
#             if, for, while, and so on.
#
# * expression dispatch: This table maps from a token to an expression handler.
#
# * keyword dispatch: This table maps from a key id to a keyword handler.
#
# * docblock verifier: This table is used to determine if a key id is allowed to
#                      have a docblock.


import (finish_file,
        open_file,
        script_name,
        token_data,
        write_table_header,
        write_numeric_table) common

script_name = "scripts/parser_data.lily"

var constants = [
    "__dir__",
    "__file__",
    "__function__",
    "__line__",
    "false",
    "self",
    "true",
    "unit",
]
var keywords = [
    "break",
    "case",
    "class",
    "constant",
    "continue",
    "define",
    "do",
    "elif",
    "else",
    "enum",
    "except",
    "for",
    "foreach",
    "forward",
    "if",
    "import",
    "match",
    "private",
    "protected",
    "public",
    "raise",
    "return",
    "scoped",
    "static",
    "try",
    "var",
    "while",
    "with",
]
var docblock_keywords = [
    "class",
    "constant",
    "define",
    "enum",
    "private",
    "protected",
    "public",
    "scoped",
    "var",
]
var expression_group_data = [
    "expr_binary" => [
        "tk_bitwise_and",
        "tk_bitwise_and_eq",
        "tk_bitwise_or",
        "tk_bitwise_or_eq",
        "tk_bitwise_xor",
        "tk_bitwise_xor_eq",
        "tk_divide",
        "tk_divide_eq",
        "tk_eq_eq",
        "tk_equal",
        "tk_func_pipe",
        "tk_gt",
        "tk_gt_eq",
        "tk_left_shift",
        "tk_left_shift_eq",
        "tk_logical_and",
        "tk_logical_or",
        "tk_lt",
        "tk_lt_eq",
        "tk_minus_eq",
        "tk_modulo",
        "tk_modulo_eq",
        "tk_multiply",
        "tk_multiply_eq",
        "tk_not_eq",
        "tk_plus",
        "tk_plus_eq",
        "tk_plus_plus",
        "tk_right_shift",
        "tk_right_shift_eq",
    ],
    "expr_close_token" => [
        "tk_colon",
        "tk_docblock",
        "tk_end_lambda",
        "tk_eof",
        "tk_left_curly",
        "tk_right_bracket",
        "tk_right_curly",
        "tk_right_parenth",
        "tk_three_dots",
        "tk_tuple_close",
    ],
    "expr_invalid" => [
        "tk_scoop",
        "tk_typecast_parenth",
    ],
    "expr_unary" => [
        "tk_tilde",
        "tk_not",
    ],
]

define shorthash(name: String): Integer
{
    var name_bytes = name.to_bytestring()
    var result = 0, shift = 0
    var stop = name_bytes.size() - 1

    if stop > 7: {
        stop = 7
    }

    for i in 0...stop: {
        result = result | (name_bytes[i].to_i() << shift)
        shift += 8
    }

    return result
}

define sort_entry(left: Tuple[String, Integer], right: Tuple[String, Integer])
    : Boolean
{
    return left[1] >= right[1]
}

define sort[A](source: List[A], cmp_func: Function(A, A => Boolean))
    : List[A]
{
    var n = source.size()
    var swapped = true

    while swapped: {
        swapped = false
        for i in 1...n-1 by 1: {
            var a = source[i - 1]
            var b = source[i]

            if cmp_func(a, b): {
                var temp = source[i]
                source[i] = source[i - 1]
                source[i - 1] = temp
                swapped = true
            }
        }

        n -= 1
    }

    return source
}

define write_header(f: File)
{
    f.write("""\
typedef struct {
    const char *name;
    uint64_t shorthash;
} keyword_entry;

typedef void (expr_handler)(lily_parse_state *, uint16_t *);
typedef void (keyword_handler)(lily_parse_state *);\n\n\
    """)
}

define write_shorthash_table(f: File, name: String,
                             table: List[Tuple[String, Integer]])
{
    var result: List[String] = []

    f.write("keyword_entry " ++ name ++ "[] =\n{\n")

    for entry in table: {
        var rec = "    {\"" ++ entry[0] ++ "\", " ++ entry[1] ++ "},\n"

        f.write(rec)
    }

    f.write("};\n\n")
}

define write_define_table(f: File, header: String,
                          table: List[Tuple[String, Integer]])
{
    var result: List[String] = []
    var names = table.map(|t| t[0].upper() )
                     .push("BAD_ID")

    for i in 0...names.size() - 1: {
        var n = names[i]
        var rec = "# define " ++ header ++ n ++ " " ++ i.to_s() ++ "\n"

        f.write(rec)
    }

    f.write("\n")
}

define write_expression_handlers(f: File)
{
    var token_names = token_data.map(|m| m[2])
    var token_to_expr_map: Hash[String, String] = []
    var forward_exprs: Hash[String, Boolean] = []
    var group_keys = expression_group_data.keys()

    # Default is tk_* -> expr_*.
    for n in token_names: {
        var e = n.replace("tk_", "expr_")

        token_to_expr_map[n] = e
        forward_exprs[e] = true
    }

    # Tokens in the group map to a different expression function.
    for k in group_keys: {
        var group = expression_group_data[k]

        for target in group: {
            var expr = token_to_expr_map[target]

            # Replace what this associates to.
            token_to_expr_map[target] = k

            # No forward for this one because it doesn't exist.
            forward_exprs[expr] = false
        }

        forward_exprs[k] = true
    }

    var forward_names = forward_exprs.select(|k, v| v)
                                     .keys()

    forward_names = sort(forward_names, (|a, b| a >= b ))

    # Write prototypes for expression functions to be used.
    for n in forward_names: {
        f.write("static void {}(lily_parse_state *, uint16_t *);\n".format(n))
    }

    f.write("\nstatic expr_handler *expr_handlers[] =\n{\n")

    # Write the token -> function table.
    for n in token_names: {
        f.write("    [{}] = {1},\n".format(n, token_to_expr_map[n]))
    }

    f.write("};\n\n")
}

define write_keyword_handlers(f: File)
{
    # Sort by shorthash order for the mapping table.
    var table_base = sort(keywords.map(|m| <[m, shorthash(m)]> ), sort_entry)

    # See ya shorthashes (only needed them for sorting).
    var table = table_base.map(|m| "keyword_" ++ m[0] )

    for t in table: {
        f.write("static void {}(lily_parse_state *);\n".format(t))
    }

    f.write("\nstatic keyword_handler *handlers[] =\n{\n")

    # Write the token -> function table.
    for t in table: {
        f.write("    {},\n".format(t))
    }

    f.write("};\n\n")
}

define write_docblock_keywords(f: File)
{
    var table = keywords.map(|m| <[m, shorthash(m)]> )
    var id_map: Hash[String, Integer] = []

    sort(table, sort_entry)
    table = table.map(|m| <[m[0], 0]> )

    for t in table: {
        for dc in docblock_keywords: {
            if t[0] == dc: {
                t[1] = 1
            }
        }
    }

    # The push covers the invalid keyword case.
    var out_table = table.map(|m| m[1] )
                         .push(0)

    write_table_header(f, "int valid_docblock_table")
    write_numeric_table(f, out_table)
}

define write_lily_parser_data
{
    var path = "src/lily_parser_data.h"
    var f = open_file(path)
    var records = [
        <[constants, "constants", "CONST_"]>,
        <[keywords,  "keywords",  "KEY_"]>,
    ]

    write_header(f)

    for r in records: {
        var table_base = r[0]
        var table = sort(table_base.map(|m| <[m, shorthash(m)]> ), sort_entry)
        var name = r[1]
        var header = r[2]

        write_shorthash_table(f, name, table)
        write_define_table(f, header, table)
    }

    write_expression_handlers(f)
    write_keyword_handlers(f)
    write_docblock_keywords(f)
    finish_file(f, path)
}

write_lily_parser_data()
